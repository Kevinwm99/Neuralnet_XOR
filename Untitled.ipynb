{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hidden weights: [0.08035579 0.97019555] [0.89613324 0.01655917]\n",
      "Initial hidden biases: [0.53526519] [0.02458115]\n",
      "Initial output weights: [0.97738563 0.77714928] [0.9536682  0.83946441]\n",
      "Initial output biases: [0.4137334] [0.63401393]\n"
     ]
    }
   ],
   "source": [
    "inputs =np.array([[1 ,-1 ,-1, 1],[1, -1, 1, -1]])\n",
    "expected_output =np.array([[1 ,1 ,0, 0],[0, 0, 1, 1]])\n",
    "epochs=10000\n",
    "lr=0.1\n",
    "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,2\n",
    "\n",
    "#Random weights and bias initialization\n",
    "hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
    "hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons)).T\n",
    "output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n",
    "output_bias = np.random.uniform(size=(1,outputLayerNeurons)).T\n",
    "\n",
    "print(\"Initial hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Initial hidden biases: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Initial output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Initial output biases: \",end='')\n",
    "print(*output_bias)\n",
    "# print(\"Initial hidden weights: \",end='')\n",
    "# print(*hidden_weights)\n",
    "# print(\"Initial hidden biases: \",end='')\n",
    "# print(*hidden_bias)\n",
    "# print(\"Initial output weights: \",end='')\n",
    "# print(*hidden_weights2)\n",
    "# print(\"Initial output biases: \",end='')\n",
    "# print(*hidden_bias2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final hidden weights: [3.91179767 3.9118528 ] [4.19636419 4.19646344]\n",
      "Final hidden bias: [-3.90798812] [4.00207945]\n",
      "Final output weights: [ 6.97226485 -6.7049254 ] [-6.96545663  6.69836741]\n",
      "Final output bias: [3.15883356] [-3.15569876]\n",
      "Final D_last: [-0.00124382 -0.00185707  0.00124731  0.00124733] [ 0.0012515   0.0018677  -0.00125482 -0.00125484]\n",
      "Final d1: [-3.33122170e-04 -2.08595347e-07  3.36523174e-04  3.36493018e-04] [ 6.92299038e-08  3.01794865e-04 -2.95556952e-04 -2.95618350e-04]\n",
      "\n",
      "Output from neural network after 10,000 epochs: [0.96408122 0.95592392 0.03597019 0.03597049] [0.03603158 0.04420498 0.96391967 0.96391937]\n"
     ]
    }
   ],
   "source": [
    "hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
    "hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons)).T\n",
    "output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n",
    "output_bias = np.random.uniform(size=(1,outputLayerNeurons)).T\n",
    "for _ in range(10000):\n",
    "    #forward pass\n",
    "    hidden_layer_activation = np.dot(hidden_weights,(inputs))+hidden_bias\n",
    "    hidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "    output_layer_activation = np.dot(output_weights,hidden_layer_output)+output_bias\n",
    "    predicted_output = sigmoid(output_layer_activation)\n",
    "    #calculate derivative\n",
    "    derivative=sigmoid_derivative(hidden_layer_output)\n",
    "    derivative2=sigmoid_derivative(predicted_output)\n",
    "    #calculate D\n",
    "    D_last=(predicted_output-expected_output)*derivative2\n",
    "    #Backpropagation\n",
    "\n",
    "    \n",
    "    d1=np.dot(output_weights.T,D_last)*derivative\n",
    "\n",
    "\n",
    "    #Updating Weights and Biases\n",
    "    output_weights=output_weights-lr*np.dot(D_last,hidden_layer_output.T)\n",
    "    output_bias=output_bias-lr*np.sum(D_last,keepdims=True,axis=1)\n",
    "    hidden_weights=hidden_weights-lr*np.dot(d1,(inputs).T)\n",
    "    hidden_bias=hidden_bias-lr*np.sum(d1,keepdims=True,axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     output_weights += -(d_predicted_output).dot(hidden_layer_output.T) * lr\n",
    "#     output_bias += -np.sum(d_predicted_output) * lr\n",
    "#     hidden_weights += -(d_hidden_layer).dot(sigmoid(inputs.T)) * lr\n",
    "#     hidden_bias += -np.sum(d_hidden_layer) * lr\n",
    "print(\"Final hidden weights: \",end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Final hidden bias: \",end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Final output weights: \",end='')\n",
    "print(*output_weights)\n",
    "print(\"Final output bias: \",end='')\n",
    "print(*output_bias)\n",
    "\n",
    "\n",
    "print(\"Final D_last: \",end='')\n",
    "print(*D_last)\n",
    "print(\"Final d1: \",end='')\n",
    "print(*d1)\n",
    "\n",
    "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
    "print(*predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]]\n",
      "[[0.03596821]\n",
      " [0.96392166]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_test=np.array([[0],[0]])\n",
    "print(input_test)\n",
    "hidden_layer_activation = np.dot(hidden_weights,(input_test))+hidden_bias\n",
    "#     hidden_layer_activation += hidden_bias\n",
    "hidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "\n",
    "output_layer_activation = np.dot(output_weights,hidden_layer_output)+output_bias\n",
    "#     output_layer_activation += output_bias\n",
    "predicted_output = sigmoid(output_layer_activation)\n",
    "print(predicted_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
